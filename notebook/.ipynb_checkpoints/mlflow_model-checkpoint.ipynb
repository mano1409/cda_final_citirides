{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2424124-460d-4f5b-a2cc-2fd4068a0e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Registered Model 'CitiBikeForecasting'…\n",
      "Registering runs:/xxxxxxxxxxxxxxxxxxxxxxxxxxxxx/model as a new version of 'CitiBikeForecasting'…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/10 15:28:18 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: CitiBikeForecasting, version 1\n",
      "/var/folders/23/k8hnw3gn5y7dtlgzrjcgdyhc0000gn/T/ipykernel_26137/1705479191.py:62: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Registered as version 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/10 15:28:18 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: CitiBikeForecasting, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Transitioned version 1 to 'Staging'\n",
      "\n",
      "Registering runs:/yyyyyyyyyyyyyyyyyyyyyyyyyyy/model as a new version of 'CitiBikeForecasting'…\n",
      " → Registered as version 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/10 15:28:19 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: CitiBikeForecasting, version 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Transitioned version 2 to 'Staging'\n",
      "\n",
      "Registering runs:/zzzzzzzzzzzzzzzzzzzzzzzzzzz/model as a new version of 'CitiBikeForecasting'…\n",
      " → Registered as version 3\n",
      " → Transitioned version 3 to 'Staging'\n",
      "\n",
      "✅ All done. Check your DagsHub Model Registry under CitiBikeForecasting\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "register_models.py\n",
    "\n",
    "Register three existing MLflow runs (each with a logged \"model\" artifact)\n",
    "as versions of the same Registered Model on DagsHub.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# DAGS-HUB MLflow CONFIGURATION\n",
    "MLFLOW_TRACKING_URI      = \"https://dagshub.com/kaushal-shivaprakashan/final_project.mlflow\"\n",
    "MLFLOW_TRACKING_USERNAME = \"kaushal-shivaprakashan\"\n",
    "MLFLOW_TRACKING_PASSWORD = \"b01d7b8c94b982d47d0224ea469bbfe4b8870ff6\"\n",
    "\n",
    "# replace these with your actual run IDs\n",
    "BASELINE_RUN_ID = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "LAG28_RUN_ID    = \"yyyyyyyyyyyyyyyyyyyyyyyyyyy\"\n",
    "TOP10IMP_RUN_ID = \"zzzzzzzzzzzzzzzzzzzzzzzzzzz\"\n",
    "\n",
    "# The name of the Registered Model to create/use\n",
    "REGISTERED_MODEL_NAME = \"CitiBikeForecasting\"\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# 1️⃣ Set up MLflow to point at your DagsHub endpoint with basic auth\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = MLFLOW_TRACKING_USERNAME\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = MLFLOW_TRACKING_PASSWORD\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "def register_run(run_id: str, model_name: str, client: MlflowClient):\n",
    "    \"\"\"\n",
    "    Registers the model artifact from a given run_id as a new version\n",
    "    in `model_name`.\n",
    "    \"\"\"\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "    print(f\"Registering {model_uri} as a new version of '{model_name}'…\")\n",
    "    mv = client.create_model_version(\n",
    "        name=model_name,\n",
    "        source=model_uri,\n",
    "        run_id=run_id,\n",
    "    )\n",
    "    print(f\" → Registered as version {mv.version}\")\n",
    "    return mv\n",
    "\n",
    "def main():\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # Ensure the Registered Model exists (idempotent)\n",
    "    try:\n",
    "        client.get_registered_model(REGISTERED_MODEL_NAME)\n",
    "        print(f\"Registered Model '{REGISTERED_MODEL_NAME}' already exists.\")\n",
    "    except mlflow.exceptions.RestException:\n",
    "        print(f\"Creating Registered Model '{REGISTERED_MODEL_NAME}'…\")\n",
    "        client.create_registered_model(REGISTERED_MODEL_NAME)\n",
    "\n",
    "    # Register each run and transition to Staging\n",
    "    for run_id in [BASELINE_RUN_ID, LAG28_RUN_ID, TOP10IMP_RUN_ID]:\n",
    "        mv = register_run(run_id, REGISTERED_MODEL_NAME, client)\n",
    "        client.transition_model_version_stage(\n",
    "            name=REGISTERED_MODEL_NAME,\n",
    "            version=mv.version,\n",
    "            stage=\"Staging\",\n",
    "            archive_existing_versions=False,\n",
    "        )\n",
    "        print(f\" → Transitioned version {mv.version} to 'Staging'\\n\")\n",
    "\n",
    "    print(\"✅ All done. Check your DagsHub Model Registry under\", REGISTERED_MODEL_NAME)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a02a3636-34a0-4804-b7e2-6c5949b2b3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/10 15:30:07 INFO mlflow.tracking.fluent: Experiment with name 'CitiBike_Remote_Experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[baseline] MAE = 31.20\n",
      "🏃 View run baseline_mean at: https://dagshub.com/kaushal-shivaprakashan/final_project.mlflow/#/experiments/0/runs/bc294ae85d6a41d19346bafdce4518c5\n",
      "🧪 View experiment at: https://dagshub.com/kaushal-shivaprakashan/final_project.mlflow/#/experiments/0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5326\n",
      "[LightGBM] [Info] Number of data points in the train set: 6582, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 45.662413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/05/10 15:30:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[lgbm_28lag] MAE = 8.22\n",
      "🏃 View run lgbm_28lag at: https://dagshub.com/kaushal-shivaprakashan/final_project.mlflow/#/experiments/0/runs/f205531465e347f4ac2719fb2df7b3b1\n",
      "🧪 View experiment at: https://dagshub.com/kaushal-shivaprakashan/final_project.mlflow/#/experiments/0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5326\n",
      "[LightGBM] [Info] Number of data points in the train set: 6582, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 45.662413\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6582, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 45.662413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/05/10 15:30:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[lgbm_top10_imp] MAE = 8.33\n",
      "🏃 View run lgbm_top10_imp at: https://dagshub.com/kaushal-shivaprakashan/final_project.mlflow/#/experiments/0/runs/c4b45d6d42024e72b74aab6ecef5b727\n",
      "🧪 View experiment at: https://dagshub.com/kaushal-shivaprakashan/final_project.mlflow/#/experiments/0\n",
      "\n",
      "✅ All three models have been logged under experiment 'CitiBike_Remote_Experiment'\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "train_and_log_all.py\n",
    "\n",
    "Loads cleaned Citibike data, then:\n",
    "  1) logs a baseline mean model\n",
    "  2) logs a LightGBM on 28 lag features\n",
    "  3) logs a LightGBM on top-10 importance features\n",
    "\n",
    "All runs go to your DagsHub MLflow server.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from lightgbm import LGBMRegressor\n",
    "import mlflow\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# DagsHub MLflow settings\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"kaushal-shivaprakashan\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"b01d7b8c94b982d47d0224ea469bbfe4b8870ff6\"\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/kaushal-shivaprakashan/final_project.mlflow\")\n",
    "\n",
    "# Experiment name under which the three runs will appear\n",
    "EXPERIMENT_NAME = \"CitiBike_Remote_Experiment\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# Data & split config\n",
    "PARQUET_PATH = \"/Users/kaushalshivaprakash/Desktop/project3/data/processed/cleaned_citibike/citibike_2023_top3.parquet\"\n",
    "TRAIN_FRAC   = 0.8\n",
    "MAX_LAG      = 28\n",
    "TOP_K        = 10\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def load_and_agg(path):\n",
    "    df = pd.read_parquet(path)\n",
    "    df[\"datetime\"] = df[\"started_at\"].dt.floor(\"H\")\n",
    "    agg = df.groupby(\"datetime\").size().reset_index(name=\"count\").sort_values(\"datetime\")\n",
    "    return agg\n",
    "\n",
    "def train_test_split_ts(df, frac):\n",
    "    idx = int(len(df) * frac)\n",
    "    return df.iloc[:idx], df.iloc[idx:]\n",
    "\n",
    "def log_baseline(train, test):\n",
    "    with mlflow.start_run(run_name=\"baseline_mean\"):\n",
    "        pred = train[\"count\"].mean()\n",
    "        mae = mean_absolute_error(test[\"count\"], [pred]*len(test))\n",
    "        mlflow.log_param(\"model_type\", \"baseline_mean\")\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        print(f\"[baseline] MAE = {mae:.2f}\")\n",
    "\n",
    "def log_lag_model(df):\n",
    "    df_lag = df.copy()\n",
    "    for lag in range(1, MAX_LAG+1):\n",
    "        df_lag[f\"lag_{lag}\"] = df_lag[\"count\"].shift(lag)\n",
    "    df_lag = df_lag.dropna().reset_index(drop=True)\n",
    "    train, test = train_test_split_ts(df_lag, TRAIN_FRAC)\n",
    "    feats = [f\"lag_{i}\" for i in range(1, MAX_LAG+1)]\n",
    "    X_train, y_train = train[feats], train[\"count\"]\n",
    "    X_test,  y_test  = test[feats],  test[\"count\"]\n",
    "\n",
    "    with mlflow.start_run(run_name=\"lgbm_28lag\"):\n",
    "        mlflow.log_param(\"model_type\", \"lgbm_28lag\")\n",
    "        mlflow.log_param(\"num_lags\", MAX_LAG)\n",
    "        model = LGBMRegressor(random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        print(f\"[lgbm_28lag] MAE = {mae:.2f}\")\n",
    "\n",
    "def log_topk_model(df):\n",
    "    # build full-lag dataset\n",
    "    df_lag = df.copy()\n",
    "    for lag in range(1, MAX_LAG+1):\n",
    "        df_lag[f\"lag_{lag}\"] = df_lag[\"count\"].shift(lag)\n",
    "    df_lag = df_lag.dropna().reset_index(drop=True)\n",
    "    train, test = train_test_split_ts(df_lag, TRAIN_FRAC)\n",
    "    feats = [f\"lag_{i}\" for i in range(1, MAX_LAG+1)]\n",
    "    X_train, y_train = train[feats], train[\"count\"]\n",
    "    X_test,  y_test  = test[feats],  test[\"count\"]\n",
    "\n",
    "    # get importances\n",
    "    base = LGBMRegressor(random_state=42)\n",
    "    base.fit(X_train, y_train)\n",
    "    importances = pd.Series(base.feature_importances_, index=feats)\n",
    "    top_feats = importances.nlargest(TOP_K).index.tolist()\n",
    "\n",
    "    with mlflow.start_run(run_name=\"lgbm_top10_imp\"):\n",
    "        mlflow.log_param(\"model_type\", \"lgbm_top10_imp\")\n",
    "        mlflow.log_param(\"num_lags\", MAX_LAG)\n",
    "        mlflow.log_param(\"selected_feats\", top_feats)\n",
    "        model = LGBMRegressor(random_state=42)\n",
    "        model.fit(X_train[top_feats], y_train)\n",
    "        preds = model.predict(X_test[top_feats])\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        print(f\"[lgbm_top10_imp] MAE = {mae:.2f}\")\n",
    "\n",
    "def main():\n",
    "    df = load_and_agg(PARQUET_PATH)\n",
    "    train, test = train_test_split_ts(df, TRAIN_FRAC)\n",
    "\n",
    "    # 1) Baseline\n",
    "    log_baseline(train, test)\n",
    "    # 2) 28-lag\n",
    "    log_lag_model(df)\n",
    "    # 3) Top-10 importance\n",
    "    log_topk_model(df)\n",
    "\n",
    "    print(f\"\\n✅ All three models have been logged under experiment '{EXPERIMENT_NAME}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42d240ca-cbc9-4051-ba3b-c7961d46f9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[baseline_mean] MAE = 31.20\n",
      "🏃 View run baseline_mean at: https://dagshub.com/kaushal-shivaprakashan/final_project.mlflow/#/experiments/0/runs/26072956d953438a9f1274ce4ab9d1e3\n",
      "🧪 View experiment at: https://dagshub.com/kaushal-shivaprakashan/final_project.mlflow/#/experiments/0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5326\n",
      "[LightGBM] [Info] Number of data points in the train set: 6582, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 45.662413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/05/10 15:33:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[lgbm_28lag] MAE = 8.22 | Δ = 22.98 (73.7%)\n",
      "🏃 View run lgbm_28lag at: https://dagshub.com/kaushal-shivaprakashan/final_project.mlflow/#/experiments/0/runs/305b68c9cd9c463fb359e5b715a94872\n",
      "🧪 View experiment at: https://dagshub.com/kaushal-shivaprakashan/final_project.mlflow/#/experiments/0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5326\n",
      "[LightGBM] [Info] Number of data points in the train set: 6582, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 45.662413\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6582, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 45.662413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/05/10 15:33:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[lgbm_top10_imp] MAE = 8.33 | Δ = 22.86 (73.3%)\n",
      "🏃 View run lgbm_top10_imp at: https://dagshub.com/kaushal-shivaprakashan/final_project.mlflow/#/experiments/0/runs/a23fe245e27341f182e28050d5b60992\n",
      "🧪 View experiment at: https://dagshub.com/kaushal-shivaprakashan/final_project.mlflow/#/experiments/0\n",
      "\n",
      "✅ Best model: 'lgbm_28lag' with MAE = 8.22\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "train_and_log_all.py\n",
    "\n",
    "Loads cleaned Citibike data, then:\n",
    "  1) logs a baseline mean model\n",
    "  2) logs a LightGBM on 28 lag features\n",
    "  3) logs a LightGBM on top-10 importance features\n",
    "\n",
    "Each run logs:\n",
    "  - mae\n",
    "  - mae_improvement = baseline_mae - mae\n",
    "  - pct_improvement = (baseline_mae - mae) / baseline_mae\n",
    "\n",
    "At the end, prints out which model performed best (lowest MAE).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from lightgbm import LGBMRegressor\n",
    "import mlflow\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# DagsHub MLflow settings\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"kaushal-shivaprakashan\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"b01d7b8c94b982d47d0224ea469bbfe4b8870ff6\"\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/kaushal-shivaprakashan/final_project.mlflow\")\n",
    "\n",
    "EXPERIMENT_NAME = \"CitiBike_Remote_Experiment\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# Data & split config\n",
    "PARQUET_PATH = \"/Users/kaushalshivaprakash/Desktop/project3/data/processed/cleaned_citibike/citibike_2023_top3.parquet\"\n",
    "TRAIN_FRAC   = 0.8\n",
    "MAX_LAG      = 28\n",
    "TOP_K        = 10\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def load_and_agg(path):\n",
    "    df = pd.read_parquet(path)\n",
    "    df[\"datetime\"] = df[\"started_at\"].dt.floor(\"H\")\n",
    "    agg = df.groupby(\"datetime\").size().reset_index(name=\"count\")\n",
    "    return agg.sort_values(\"datetime\").reset_index(drop=True)\n",
    "\n",
    "def train_test_split_ts(df, frac):\n",
    "    idx = int(len(df) * frac)\n",
    "    return df.iloc[:idx], df.iloc[idx:]\n",
    "\n",
    "def log_baseline(train, test):\n",
    "    with mlflow.start_run(run_name=\"baseline_mean\"):\n",
    "        pred = train[\"count\"].mean()\n",
    "        mae = mean_absolute_error(test[\"count\"], [pred] * len(test))\n",
    "        mlflow.log_param(\"model_type\", \"baseline_mean\")\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        print(f\"[baseline_mean] MAE = {mae:.2f}\")\n",
    "        return mae\n",
    "\n",
    "def log_lag_model(df, baseline_mae):\n",
    "    df_lag = df.copy()\n",
    "    for lag in range(1, MAX_LAG + 1):\n",
    "        df_lag[f\"lag_{lag}\"] = df_lag[\"count\"].shift(lag)\n",
    "    df_lag = df_lag.dropna().reset_index(drop=True)\n",
    "    train, test = train_test_split_ts(df_lag, TRAIN_FRAC)\n",
    "    feats = [f\"lag_{i}\" for i in range(1, MAX_LAG + 1)]\n",
    "    X_train, y_train = train[feats], train[\"count\"]\n",
    "    X_test,  y_test  = test[feats], test[\"count\"]\n",
    "\n",
    "    with mlflow.start_run(run_name=\"lgbm_28lag\"):\n",
    "        mlflow.log_param(\"model_type\", \"lgbm_28lag\")\n",
    "        mlflow.log_param(\"num_lags\", MAX_LAG)\n",
    "\n",
    "        model = LGBMRegressor(random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "\n",
    "        imp_abs = baseline_mae - mae\n",
    "        imp_pct = imp_abs / baseline_mae if baseline_mae else 0.0\n",
    "\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mae_improvement\", imp_abs)\n",
    "        mlflow.log_metric(\"pct_improvement\", imp_pct)\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "        print(f\"[lgbm_28lag] MAE = {mae:.2f} | Δ = {imp_abs:.2f} ({imp_pct:.1%})\")\n",
    "        return mae\n",
    "\n",
    "def log_topk_model(df, baseline_mae):\n",
    "    df_lag = df.copy()\n",
    "    for lag in range(1, MAX_LAG + 1):\n",
    "        df_lag[f\"lag_{lag}\"] = df_lag[\"count\"].shift(lag)\n",
    "    df_lag = df_lag.dropna().reset_index(drop=True)\n",
    "    train, test = train_test_split_ts(df_lag, TRAIN_FRAC)\n",
    "    feats = [f\"lag_{i}\" for i in range(1, MAX_LAG + 1)]\n",
    "    X_train, y_train = train[feats], train[\"count\"]\n",
    "    X_test,  y_test  = test[feats],  test[\"count\"]\n",
    "\n",
    "    # initial fit to get importances\n",
    "    base = LGBMRegressor(random_state=42)\n",
    "    base.fit(X_train, y_train)\n",
    "    importances = pd.Series(base.feature_importances_, index=feats)\n",
    "    top_feats = importances.nlargest(TOP_K).index.tolist()\n",
    "\n",
    "    with mlflow.start_run(run_name=\"lgbm_top10_imp\"):\n",
    "        mlflow.log_param(\"model_type\", \"lgbm_top10_imp\")\n",
    "        mlflow.log_param(\"num_lags\", MAX_LAG)\n",
    "        mlflow.log_param(\"selected_feats\", top_feats)\n",
    "\n",
    "        model = LGBMRegressor(random_state=42)\n",
    "        model.fit(X_train[top_feats], y_train)\n",
    "        preds = model.predict(X_test[top_feats])\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "\n",
    "        imp_abs = baseline_mae - mae\n",
    "        imp_pct = imp_abs / baseline_mae if baseline_mae else 0.0\n",
    "\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mae_improvement\", imp_abs)\n",
    "        mlflow.log_metric(\"pct_improvement\", imp_pct)\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "        print(f\"[lgbm_top10_imp] MAE = {mae:.2f} | Δ = {imp_abs:.2f} ({imp_pct:.1%})\")\n",
    "        return mae\n",
    "\n",
    "def main():\n",
    "    df = load_and_agg(PARQUET_PATH)\n",
    "    train, test = train_test_split_ts(df, TRAIN_FRAC)\n",
    "\n",
    "    # Train/log and collect MAEs\n",
    "    maes = {}\n",
    "    maes[\"baseline_mean\"]   = log_baseline(train, test)\n",
    "    maes[\"lgbm_28lag\"]      = log_lag_model(df, maes[\"baseline_mean\"])\n",
    "    maes[\"lgbm_top10_imp\"]  = log_topk_model(df, maes[\"baseline_mean\"])\n",
    "\n",
    "    # Determine best model (lowest MAE)\n",
    "    best_model = min(maes, key=maes.get)\n",
    "    best_mae   = maes[best_model]\n",
    "    print(f\"\\n✅ Best model: '{best_model}' with MAE = {best_mae:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f1858a-fe9d-47d1-9ee6-1a3b404100c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
