{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98cd8865-1186-4db3-a0e4-eb7b32eeb3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 17:04:31,820 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 17:04:31,824 INFO: Initializing external client\n",
      "2025-05-10 17:04:31,825 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-05-10 17:04:32,498 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1213683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |█| Rows 8256/8256 | Elapsed Time: 00:01 | Remainin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: citi_bike_hourly_counts_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1213683/jobs/named/citi_bike_hourly_counts_1_offline_fg_materialization/executions\n",
      "→ Inserted 8256 rows into Feature Group 'citi_bike_hourly_counts'\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1213683/fs/1202283/fg/1454618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |█| Rows 8228/8228 | Elapsed Time: 00:00 | Remainin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: citi_bike_hourly_predictions_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1213683/jobs/named/citi_bike_hourly_predictions_1_offline_fg_materialization/executions\n",
      "→ Inserted 8228 rows into Feature Group 'citi_bike_hourly_predictions'\n",
      "→ Best run: 305b68c9cd9c463fb359e5b715a94872 with MAE = 8.22\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "The destination path for downloaded artifacts does not exist! Destination path: /Users/kaushalshivaprakash/Desktop/project3/pipelines/best_model_artifact",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 114\u001b[39m\n\u001b[32m    111\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m→ Registered model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHOPS_MODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhs_model.version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in Hopsworks\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 98\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshutil\u001b[39;00m\n\u001b[32m     97\u001b[39m     shutil.rmtree(model_local_path)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_local_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m→ Downloaded model artifacts to ./\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_local_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# 7. Register that model in Hopsworks Model Registry\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kaushal/lib/python3.11/site-packages/mlflow/tracking/client.py:3308\u001b[39m, in \u001b[36mMlflowClient.download_artifacts\u001b[39m\u001b[34m(self, run_id, path, dst_path)\u001b[39m\n\u001b[32m   3261\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdownload_artifacts\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_id: \u001b[38;5;28mstr\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m, dst_path: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m   3262\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3263\u001b[39m \u001b[33;03m    Download an artifact file or directory from a run to a local directory if applicable,\u001b[39;00m\n\u001b[32m   3264\u001b[39m \u001b[33;03m    and return a local path for it.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3306\u001b[39m \u001b[33;03m        Artifacts: ['features.txt']\u001b[39;00m\n\u001b[32m   3307\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3308\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tracking_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kaushal/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/client.py:997\u001b[39m, in \u001b[36mTrackingServiceClient.download_artifacts\u001b[39m\u001b[34m(self, run_id, path, dst_path)\u001b[39m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdownload_artifacts\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_id, path, dst_path=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    981\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Download an artifact file or directory from a run to a local directory if applicable,\u001b[39;00m\n\u001b[32m    982\u001b[39m \u001b[33;03m    and return a local path for it.\u001b[39;00m\n\u001b[32m    983\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    995\u001b[39m \n\u001b[32m    996\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_artifact_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kaushal/lib/python3.11/site-packages/mlflow/store/artifact/artifact_repo.py:253\u001b[39m, in \u001b[36mArtifactRepository.download_artifacts\u001b[39m\u001b[34m(self, artifact_path, dst_path)\u001b[39m\n\u001b[32m    251\u001b[39m dst_path = os.path.abspath(dst_path)\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(dst_path):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    254\u001b[39m         message=(\n\u001b[32m    255\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe destination path for downloaded artifacts does not\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    256\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m exist! Destination path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdst_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m         ),\n\u001b[32m    258\u001b[39m         error_code=RESOURCE_DOES_NOT_EXIST,\n\u001b[32m    259\u001b[39m     )\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isdir(dst_path):\n\u001b[32m    261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    262\u001b[39m         message=(\n\u001b[32m    263\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe destination path for downloaded artifacts must be a directory!\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    266\u001b[39m         error_code=INVALID_PARAMETER_VALUE,\n\u001b[32m    267\u001b[39m     )\n",
      "\u001b[31mMlflowException\u001b[39m: The destination path for downloaded artifacts does not exist! Destination path: /Users/kaushalshivaprakash/Desktop/project3/pipelines/best_model_artifact"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "ingest_to_hopsworks.py\n",
    "\n",
    "Loads hourly counts (always), optional predictions (if present),\n",
    "and the best MLflow model, then pushes them into Hopsworks\n",
    "Feature Store and Model Registry.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# LOCAL PATHS & CONFIG\n",
    "PARQUET_PATH       = \"/Users/kaushalshivaprakash/Desktop/project3/data/processed/cleaned_citibike/citibike_2023_top3.parquet\"\n",
    "PREDICTIONS_PATH   = \"/Users/kaushalshivaprakash/Desktop/project3/data/predictions.csv\"\n",
    "EXPERIMENT_NAME    = \"CitiBike_Remote_Experiment\"\n",
    "\n",
    "# Feature Group names & versions\n",
    "FG_COUNTS_NAME     = \"citi_bike_hourly_counts\"\n",
    "FG_COUNTS_VERSION  = 1\n",
    "FG_PRED_NAME       = \"citi_bike_hourly_predictions\"\n",
    "FG_PRED_VERSION    = 1\n",
    "\n",
    "# Hopsworks Model Registry name\n",
    "HOPS_MODEL_NAME    = \"CitiBikeForecasting\"\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def main():\n",
    "    # 1. Log into Hopsworks\n",
    "    project = hopsworks.login()\n",
    "    fs      = project.get_feature_store()\n",
    "    mr      = project.get_model_registry()\n",
    "\n",
    "    # 2. Load & aggregate your time-series counts\n",
    "    df = pd.read_parquet(PARQUET_PATH)\n",
    "    df[\"datetime\"] = df[\"started_at\"].dt.floor(\"H\")\n",
    "    counts = (\n",
    "        df.groupby(\"datetime\")\n",
    "          .size()\n",
    "          .reset_index(name=\"count\")\n",
    "          .sort_values(\"datetime\")\n",
    "    )\n",
    "\n",
    "    # 3. Create or get a Feature Group for counts\n",
    "    fg_counts = fs.get_feature_group(FG_COUNTS_NAME, FG_COUNTS_VERSION)\n",
    "    if fg_counts is None:\n",
    "        fg_counts = fs.create_feature_group(\n",
    "            name=FG_COUNTS_NAME,\n",
    "            version=FG_COUNTS_VERSION,\n",
    "            primary_key=[\"datetime\"],\n",
    "            event_time=\"datetime\",\n",
    "            description=\"Hourly ride counts for top-3 stations\",\n",
    "        )\n",
    "    fg_counts.insert(counts, write_options={\"wait_for_job\": False})\n",
    "    print(f\"→ Inserted {len(counts)} rows into Feature Group '{FG_COUNTS_NAME}'\")\n",
    "\n",
    "    # 4. (Optional) Load & ingest your predictions CSV if it exists\n",
    "    if os.path.exists(PREDICTIONS_PATH):\n",
    "        preds = pd.read_csv(PREDICTIONS_PATH, parse_dates=[\"datetime\"])\n",
    "        fg_preds = fs.get_feature_group(FG_PRED_NAME, FG_PRED_VERSION)\n",
    "        if fg_preds is None:\n",
    "            fg_preds = fs.create_feature_group(\n",
    "                name=FG_PRED_NAME,\n",
    "                version=FG_PRED_VERSION,\n",
    "                primary_key=[\"datetime\"],\n",
    "                event_time=\"datetime\",\n",
    "                description=\"Model predictions for hourly ride counts\",\n",
    "            )\n",
    "        fg_preds.insert(preds, write_options={\"wait_for_job\": False})\n",
    "        print(f\"→ Inserted {len(preds)} rows into Feature Group '{FG_PRED_NAME}'\")\n",
    "    else:\n",
    "        print(f\"⚠️  Predictions file not found at '{PREDICTIONS_PATH}', skipping predictions ingestion.\")\n",
    "\n",
    "    # 5. Find the best MLflow run (lowest MAE) in your experiment\n",
    "    client   = MlflowClient()\n",
    "    exp      = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    runs     = client.search_runs(\n",
    "        experiment_ids=[exp.experiment_id],\n",
    "        filter_string=\"\",\n",
    "        run_view_type=1,               # include all runs\n",
    "        max_results=1,\n",
    "        order_by=[\"metrics.mae ASC\"]   # best first\n",
    "    )\n",
    "    best_run = runs[0]\n",
    "    run_id   = best_run.info.run_id\n",
    "    best_mae = best_run.data.metrics[\"mae\"]\n",
    "    print(f\"→ Best run: {run_id} with MAE = {best_mae:.2f}\")\n",
    "\n",
    "    # 6. Download the model artifact from that run\n",
    "    model_local_path = \"best_model_artifact\"\n",
    "    if os.path.exists(model_local_path):\n",
    "        import shutil\n",
    "        shutil.rmtree(model_local_path)\n",
    "    client.download_artifacts(run_id, \"model\", dst_path=model_local_path)\n",
    "    print(f\"→ Downloaded model artifacts to ./{model_local_path}/\")\n",
    "\n",
    "    # 7. Register that model in Hopsworks Model Registry\n",
    "    hs_model = mr.python.create_model(\n",
    "        name=HOPS_MODEL_NAME,\n",
    "        metric=\"mae\",\n",
    "        metric_value=best_mae,\n",
    "        description=\"Best CitiBike forecasting model (lowest MAE)\",\n",
    "        custom={\"mlflow_run_id\": run_id},\n",
    "    )\n",
    "    hs_model.save(model_local_path)\n",
    "    hs_model.stage(\"production\")\n",
    "    print(f\"→ Registered model '{HOPS_MODEL_NAME}' version {hs_model.version} in Hopsworks\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc705f5a-50e7-411d-b6fa-f2e139f0c649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run: 305b68c9cd9c463fb359e5b715a94872 (MAE=8.22)\n",
      "Loading model from runs:/305b68c9cd9c463fb359e5b715a94872/model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d517aa630d487ba57e283c081b852f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 8228 rows to /Users/kaushalshivaprakash/Desktop/project3/data/predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "inference_run_uri.py\n",
    "\n",
    "Finds your best MLflow run (by MAE), loads its model artifact directly via run URI,\n",
    "makes forecasts on the cleaned Parquet, and writes out predictions.csv.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# CONFIG\n",
    "PARQUET_PATH    = \"/Users/kaushalshivaprakash/Desktop/project3/data/processed/cleaned_citibike/citibike_2023_top3.parquet\"\n",
    "EXPERIMENT_NAME = \"CitiBike_Remote_Experiment\"\n",
    "OUTPUT_CSV      = \"/Users/kaushalshivaprakash/Desktop/project3/data/predictions.csv\"\n",
    "\n",
    "# If you’re using DagsHub remote tracking, set these (otherwise unset)\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"kaushal-shivaprakashan\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"b01d7b8c94b982d47d0224ea469bbfe4b8870ff6\"\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/kaushal-shivaprakashan/final_project.mlflow\")\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def load_hourly_counts(path):\n",
    "    df = pd.read_parquet(path)\n",
    "    df[\"datetime\"] = df[\"started_at\"].dt.floor(\"H\")\n",
    "    agg = (\n",
    "        df.groupby(\"datetime\")\n",
    "          .size()\n",
    "          .reset_index(name=\"count\")\n",
    "          .sort_values(\"datetime\")\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "    return agg\n",
    "\n",
    "def get_best_run_id(experiment_name: str) -> str:\n",
    "    client = MlflowClient()\n",
    "    exp = client.get_experiment_by_name(experiment_name)\n",
    "    if exp is None:\n",
    "        raise ValueError(f\"Experiment '{experiment_name}' not found\")\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=[exp.experiment_id],\n",
    "        filter_string=\"\",\n",
    "        run_view_type=1,\n",
    "        max_results=1,\n",
    "        order_by=[\"metrics.mae ASC\"]\n",
    "    )\n",
    "    best = runs[0]\n",
    "    print(f\"Best run: {best.info.run_id} (MAE={best.data.metrics['mae']:.2f})\")\n",
    "    return best.info.run_id\n",
    "\n",
    "def load_model_from_run(run_id: str):\n",
    "    uri = f\"runs:/{run_id}/model\"\n",
    "    print(f\"Loading model from {uri}\")\n",
    "    return mlflow.pyfunc.load_model(uri)\n",
    "\n",
    "def build_lag_features(df, max_lag=28):\n",
    "    df = df.copy()\n",
    "    for lag in range(1, max_lag+1):\n",
    "        df[f\"lag_{lag}\"] = df[\"count\"].shift(lag)\n",
    "    return df.dropna().reset_index(drop=True)\n",
    "\n",
    "def main():\n",
    "    # 1) load counts\n",
    "    hourly = load_hourly_counts(PARQUET_PATH)\n",
    "\n",
    "    # 2) find best run\n",
    "    run_id = get_best_run_id(EXPERIMENT_NAME)\n",
    "\n",
    "    # 3) load model\n",
    "    model = load_model_from_run(run_id)\n",
    "\n",
    "    # 4) build features & predict\n",
    "    data = build_lag_features(hourly, max_lag=28)\n",
    "    feature_cols = [f\"lag_{i}\" for i in range(1, 29)]\n",
    "    data[\"prediction\"] = model.predict(data[feature_cols])\n",
    "\n",
    "    # 5) write CSV\n",
    "    out = data[[\"datetime\", \"prediction\"]]\n",
    "    os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)\n",
    "    out.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f\"Wrote {len(out)} rows to {OUTPUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693b72d1-7609-44aa-a3ae-9b564ad1c42a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
