{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2607b7e0-fc9d-4f6e-b3b6-ebfbf50258f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1,000,000 rows from 202312-citibike-tripdata_2.csv\n",
      "Loaded 1,000,000 rows from 202301-citibike-tripdata_1.csv\n",
      "Loaded 204,874 rows from 202312-citibike-tripdata_3.csv\n",
      "Loaded 453,152 rows from 202305-citibike-tripdata_4.csv\n",
      "Loaded 1,000,000 rows from 202312-citibike-tripdata_1.csv\n",
      "Loaded 795,412 rows from 202301-citibike-tripdata_2.csv\n",
      "Loaded 1,000,000 rows from 202305-citibike-tripdata_1.csv\n",
      "Loaded 1,000,000 rows from 202305-citibike-tripdata_2.csv\n",
      "Loaded 1,000,000 rows from 202305-citibike-tripdata_3.csv\n",
      "Loaded 1,000,000 rows from 202306-citibike-tripdata_2.csv\n",
      "Loaded 1,000,000 rows from 202309-citibike-tripdata_3.csv\n",
      "Loaded 1,000,000 rows from 202309-citibike-tripdata_2.csv\n",
      "Loaded 1,000,000 rows from 202306-citibike-tripdata_3.csv\n",
      "Loaded 1,000,000 rows from 202306-citibike-tripdata_1.csv\n",
      "Loaded 1,000,000 rows from 202309-citibike-tripdata_1.csv\n",
      "Loaded 451,549 rows from 202306-citibike-tripdata_4.csv\n",
      "Loaded 1,000,000 rows from 202311-citibike-tripdata_1.csv\n",
      "Loaded 696,171 rows from 202302-citibike-tripdata_2.csv\n",
      "Loaded 471,150 rows from 202309-citibike-tripdata_4.csv\n",
      "Loaded 1,000,000 rows from 202311-citibike-tripdata_2.csv\n",
      "Loaded 816,977 rows from 202311-citibike-tripdata_3.csv\n",
      "Loaded 1,000,000 rows from 202302-citibike-tripdata_1.csv\n",
      "Loaded 749,716 rows from 202304-citibike-tripdata_3.csv\n",
      "Loaded 1,000,000 rows from 202304-citibike-tripdata_2.csv\n",
      "Loaded 1,000,000 rows from 202304-citibike-tripdata_1.csv\n",
      "Loaded 1,000,000 rows from 202303-citibike-tripdata_1.csv\n",
      "Loaded 1,000,000 rows from 202310-citibike-tripdata_3.csv\n",
      "Loaded 1,000,000 rows from 202310-citibike-tripdata_2.csv\n",
      "Loaded 964,180 rows from 202308-citibike-tripdata_4.csv\n",
      "Loaded 1,000,000 rows from 202303-citibike-tripdata_2.csv\n",
      "Loaded 1,000,000 rows from 202310-citibike-tripdata_1.csv\n",
      "Loaded 118,932 rows from 202303-citibike-tripdata_3.csv\n",
      "Loaded 659,581 rows from 202307-citibike-tripdata_4.csv\n",
      "Loaded 1,000,000 rows from 202308-citibike-tripdata_1.csv\n",
      "Loaded 725,336 rows from 202310-citibike-tripdata_4.csv\n",
      "Loaded 1,000,000 rows from 202307-citibike-tripdata_1.csv\n",
      "Loaded 1,000,000 rows from 202308-citibike-tripdata_2.csv\n",
      "Loaded 1,000,000 rows from 202307-citibike-tripdata_3.csv\n",
      "Loaded 1,000,000 rows from 202307-citibike-tripdata_2.csv\n",
      "Loaded 1,000,000 rows from 202308-citibike-tripdata_3.csv\n",
      "Total rows after concat: 35,107,030\n",
      "Top 3 stations:\n",
      "  W 21 St & 6 Ave\n",
      "  Broadway & W 58 St\n",
      "  West St & Chambers St\n",
      "Dropped 794 invalid/duplicate rows\n",
      "\n",
      "✓ Saved cleaned data (365,696 rows) to /Users/kaushalshivaprakash/Desktop/project3/data/processed/cleaned_citibike/citibike_2023_top3.parquet\n",
      "\n",
      "2025-05-10 12:11:23,570 INFO: Initializing external client\n",
      "2025-05-10 12:11:23,570 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-05-10 12:11:24,329 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1213683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |█| Rows 365696/365696 | Elapsed Time: 00:09 | Rema\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: citibike_top3_trips_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1213683/jobs/named/citibike_top3_trips_1_offline_fg_materialization/executions\n",
      "✅ Data inserted to Hopsworks feature store 'citibike_top3_trips'\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "clean_preprocess_to_hopsworks.py\n",
    "\n",
    "1) Loads raw Citibike CSVs,  \n",
    "2) Cleans & feature-engineers them,  \n",
    "3) Filters to the top-K busiest start stations,  \n",
    "4) Writes out a local Parquet, AND  \n",
    "5) Pushes the DataFrame into Hopsworks Feature Store.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# LOCAL CONFIGURATION — update these to your paths\n",
    "CSV_DIR     = \"/Users/kaushalshivaprakash/Desktop/project3/data/processed/raw_citibike_csvs\"\n",
    "OUTPUT_DIR  = \"/Users/kaushalshivaprakash/Desktop/project3/data/processed/cleaned_citibike\"\n",
    "OUTPUT_FILE = os.path.join(OUTPUT_DIR, \"citibike_2023_top3.parquet\")\n",
    "TOP_K       = 3\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "COLUMNS = [\n",
    "    \"ride_id\",\"rideable_type\",\"started_at\",\"ended_at\",\n",
    "    \"start_station_name\",\"start_station_id\",\n",
    "    \"end_station_name\",\"end_station_id\",\n",
    "    \"start_lat\",\"start_lng\",\"end_lat\",\"end_lng\",\n",
    "    \"member_casual\",\n",
    "]\n",
    "\n",
    "def load_all_csvs(csv_dir: str) -> pd.DataFrame:\n",
    "    paths = glob.glob(os.path.join(csv_dir, \"*.csv\"))\n",
    "    dfs = []\n",
    "    for p in paths:\n",
    "        df = pd.read_csv(\n",
    "            p, usecols=COLUMNS,\n",
    "            dtype={\n",
    "                \"ride_id\": str,\n",
    "                \"rideable_type\": \"category\",\n",
    "                \"start_station_id\": str,\n",
    "                \"end_station_id\": str,\n",
    "                \"member_casual\": \"category\",\n",
    "            },\n",
    "        )\n",
    "        print(f\"Loaded {len(df):,} rows from {os.path.basename(p)}\")\n",
    "        dfs.append(df)\n",
    "    combined = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"Total rows after concat: {len(combined):,}\")\n",
    "    return combined\n",
    "\n",
    "def parse_and_engineer(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"started_at\"] = pd.to_datetime(df[\"started_at\"])\n",
    "    df[\"ended_at\"]   = pd.to_datetime(df[\"ended_at\"])\n",
    "    df[\"trip_duration_min\"] = (\n",
    "        (df[\"ended_at\"] - df[\"started_at\"])\n",
    "        .dt.total_seconds().div(60).clip(lower=0)\n",
    "    )\n",
    "    df[\"start_hour\"]      = df[\"started_at\"].dt.hour\n",
    "    df[\"start_dayofweek\"] = df[\"started_at\"].dt.dayofweek\n",
    "    return df\n",
    "\n",
    "def filter_top_stations(df: pd.DataFrame, k: int) -> pd.DataFrame:\n",
    "    top = df[\"start_station_name\"].value_counts().nlargest(k).index.tolist()\n",
    "    print(f\"Top {k} stations:\\n  \" + \"\\n  \".join(top))\n",
    "    return df[df[\"start_station_name\"].isin(top)].copy()\n",
    "\n",
    "def clean_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    before = len(df)\n",
    "    df = df.drop_duplicates(subset=[\"ride_id\"])\n",
    "    df = df.dropna(subset=[\n",
    "        \"started_at\",\"ended_at\",\n",
    "        \"start_station_name\",\"end_station_name\",\n",
    "        \"trip_duration_min\"\n",
    "    ])\n",
    "    df = df[df[\"trip_duration_min\"] > 0]\n",
    "    print(f\"Dropped {before - len(df):,} invalid/duplicate rows\")\n",
    "    return df\n",
    "\n",
    "def store_to_hopsworks(df: pd.DataFrame):\n",
    "    # Log in to your Hopsworks instance (uses HOPSWORKS_HOST & HOPSWORKS_API_KEY env vars)\n",
    "    project = hopsworks.login()  \n",
    "    fs = project.get_feature_store()\n",
    "    # Create (or get) a feature group\n",
    "    fg = fs.get_or_create_feature_group(\n",
    "        name=\"citibike_top3_trips\",\n",
    "        version=1,\n",
    "        primary_key=[\"ride_id\"],\n",
    "        description=\"Cleaned Citibike 2023 trips for top-3 busiest start stations\"\n",
    "    )\n",
    "    # Insert your DataFrame\n",
    "    fg.insert(df, write_options={\"wait_for_job\": False})\n",
    "    print(\"✅ Data inserted to Hopsworks feature store 'citibike_top3_trips'\")\n",
    "\n",
    "def main():\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # 1. Load & concat\n",
    "    df = load_all_csvs(CSV_DIR)\n",
    "\n",
    "    # 2. Parse & engineer\n",
    "    df = parse_and_engineer(df)\n",
    "\n",
    "    # 3. Filter to top-K stations\n",
    "    df = filter_top_stations(df, TOP_K)\n",
    "\n",
    "    # 4. Final cleaning\n",
    "    df = clean_df(df)\n",
    "\n",
    "    # 5. Persist locally\n",
    "    df.to_parquet(OUTPUT_FILE, index=False)\n",
    "    print(f\"\\n✓ Saved cleaned data ({len(df):,} rows) to {OUTPUT_FILE}\\n\")\n",
    "\n",
    "    # 6. Push to Hopsworks\n",
    "    store_to_hopsworks(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93cc530-f901-4a8f-8667-713fb68888c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
